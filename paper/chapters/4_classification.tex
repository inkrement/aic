\section{Classification}


%Ideen:
%\begin{enumerate}
%\item Supervised vs. unsupervised
%\item Training Set
%\item FeatureVector
%\item N-Grams
%\end{enumerate}
%

Sentiment analysis of twitter data, or more general, the idea of extracting sentiment and opinions from pieces of text is based on the more general principle of \emph{classification} \cite{Pang2002}. The broad aim of classification is to assign given textual units to a set of classes or categories or the apply some kind of regression or ranking. Sentiment analysis is a specialization of this approach which aims at assigning sentiment values to documents. One application might involve to classify an opinionated text by assigning one of two opposing sentiment polarities, i.e. classifying it as either \emph{positive} or \emph{negative}. This classification task is also referred to as \emph{binary classification} or \emph{sentiment polarity classification} \cite{Pang2002}. But in general, the input to the sentiment classification process is not strictly opinionated which makes this task challenging. Therefore this kind of binary classification might not always be applicable. Different approaches that allow for a more fine grained classification might be appropriate, for example, based on a multi-point scale that allows for more than just two sentiment classes.

The characteristics of twitter messages introduce further challenges. Due to the structure of these messages, sentiment analysis of tweets is different from analysing conventional texts, such as review documents, in various ways. The length of at most 140 characters and the rather informal spelling style pose problems that have to be considered carefully when analysing the data. When preprocessing the texts these aspects already need to be handled so that the actual classification process is supplied with information that is considered useful for the analysis phase. After this step it is necessary to collect the relevant information as so called \emph{features} and organize them into a \emph{feature vector}.

\subsection{Features}

TODO

\subsection{Methods}

For the actual classification process extent literature distinguishes two general types of techniques, namely \emph{machine learning} and \emph{semantic orientation} \cite{Ye20096527}. The machine learning approach is also referred to as \emph{supervised learning}, since corresponding techniques generally require supervised training phases. Accordingly, semantic orientation is also called \emph{unsupervised learning} because such a training phase is not necessary for the process to work. The most prominent machine learning methods comprise \emph{support vector machines} and the \emph{Na\"ive Bayes} classifier.

\subsubsection*{Na\"ive Bayes}

TODO

\begin{equation*}
P(c \vert d) = \frac{P(c)P(d \vert c)}{P(d)}
\end{equation*}

\begin{equation*}
P_{\mathrm{NB}}(c \vert d) := \frac{P(c)(\prod^{m}_{i=1}P(f_i \vert c)^{n_i(d)})}{P(d)}
\end{equation*}

\subsubsection*{Maimum Entropy}

TODO

\begin{equation*}
P_{\mathrm{ME}}(c \vert d) := \frac{1}{Z(d)}\mathrm{exp}\left( \sum_{i} \lambda_{i,c} F_{i,c}(d,c) \right)
\end{equation*}

\subsubsection*{Support Vector Machines}

TODO

\subsubsection*{Further techniques}

TODO